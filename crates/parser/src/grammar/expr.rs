use syntax::TokenKind;

use crate::{parser::marker::Marker, token_set::TokenSet, ExpectedSyntax};

use super::*;

pub(super) fn parse_expr(
    p: &mut Parser,
    expected_syntax_name: &'static str,
) -> Option<CompletedMarker> {
    parse_expr_bp(p, 0, TokenSet::NONE, expected_syntax_name)
}

#[allow(unused)]
pub(super) fn parse_expr_with_recovery_set(
    p: &mut Parser,
    expected_syntax_name: &'static str,
    recovery_set: TokenSet,
) -> Option<CompletedMarker> {
    parse_expr_bp(p, 0, recovery_set, expected_syntax_name)
}

pub(super) fn parse_ty(
    p: &mut Parser,
    expected_syntax_name: &'static str,
    recovery_set: TokenSet,
) -> Option<CompletedMarker> {
    let cm = parse_lhs(p, recovery_set, expected_syntax_name)?;
    let cm = parse_post_operators(p, recovery_set, cm, true, true);

    let m = cm.precede(p);
    Some(m.complete(p, NodeKind::Ty))
}

// this is used so that certain postfix operators are applied after prefix operators.
//
// notably, this allows `^foo^` to be parsed as `(^foo)^` and not `^(foo^)`
// and `^foo.(bar)` to be parsed as `(^foo).(bar)` and not `^(foo.(bar))`
//
// although that last one only works if `no_dot_instantiation=true`
fn parse_expr_for_prefix(
    p: &mut Parser,
    recovery_set: TokenSet,
    expected_syntax_name: &'static str,
    disallow_dot_instantiation: bool,
) -> Option<CompletedMarker> {
    let cm = parse_lhs(p, recovery_set, expected_syntax_name)?;
    Some(parse_post_operators(
        p,
        recovery_set,
        cm,
        true,
        disallow_dot_instantiation,
    ))
}

// bp stands for binding power
// look at online resources for more
fn parse_expr_bp(
    p: &mut Parser,
    minimum_bp: u8,
    recovery_set: TokenSet,
    expected_syntax_name: &'static str,
) -> Option<CompletedMarker> {
    let mut lhs = parse_lhs(p, recovery_set, expected_syntax_name)?;

    loop {
        lhs = parse_post_operators(p, recovery_set, lhs, false, false);

        if p.at_set(stmt::QUICK_ASSIGN_OPERATORS)
            && p.at_ahead(1, TokenSet::new([TokenKind::Equals]))
        {
            // don't parse +=, -=, etc. as expressions, and let `stmt.rs` handle those
            break;
        }

        let (left_bp, right_bp) = if p.at(TokenKind::DoublePipe) {
            (1, 2)
        } else if p.at(TokenKind::DoubleAnd) {
            (3, 4)
        } else if p.at_set(TokenSet::new([
            TokenKind::Left,
            TokenKind::LeftEquals,
            TokenKind::Right,
            TokenKind::RightEquals,
            TokenKind::DoubleEquals,
            TokenKind::BangEquals,
        ])) {
            (5, 6)
        } else if p.at_set(TokenSet::new([
            TokenKind::Plus,
            TokenKind::Hyphen,
            TokenKind::Pipe,
            TokenKind::Tilde,
        ])) {
            (7, 8)
        } else if p.at_set(TokenSet::new([
            TokenKind::Asterisk,
            TokenKind::Slash,
            TokenKind::Percent,
            TokenKind::And,
            TokenKind::DoubleLeft,
            TokenKind::DoubleRight,
        ])) {
            (9, 10)
        } else {
            break;
        };

        if left_bp < minimum_bp {
            break;
        }

        p.bump(); // bump operator

        let m = lhs.precede(p);
        parse_expr_bp(p, right_bp, recovery_set, "operand");
        lhs = m.complete(p, NodeKind::BinaryExpr);
    }

    Some(lhs)
}

const PREFIX_TOKENS: TokenSet = TokenSet::new([
    TokenKind::Hyphen,
    TokenKind::Plus,
    TokenKind::Bang,
    TokenKind::Tilde,
]);

// this is so `!u64.(42)` gets parsed as `(!u64).(42)` and not `!(u64.(42))`
// BUT this doesn't happen for the other prefixes because it might not be expected
// e.g. for `~u64.(42)`, the type `~u64` doesn't exist, and you ARE trying to do `~(u64.(42))`
//
// todo: add TokenKind::Bang to this list and implement inferred error unions
const PREFIX_DISALLOW_DOT: TokenSet = TokenSet::new([]);

fn parse_lhs(
    p: &mut Parser,
    recovery_set: TokenSet,
    expected_syntax_name: &'static str,
) -> Option<CompletedMarker> {
    let _guard = p.expected_syntax_name(expected_syntax_name);

    // println!("parse_lhs @ {:?}", p.peek());

    const LOOP_TOKENS: TokenSet = TokenSet::new([TokenKind::While, TokenKind::Loop]);

    let cm = if p.at(TokenKind::Int) || p.at(TokenKind::Hex) || p.at(TokenKind::Bin) {
        parse_int_literal(p)
    } else if p.at(TokenKind::Float) {
        parse_float_literal(p)
    } else if p.at(TokenKind::Bool) {
        parse_bool_literal(p)
    } else if p.at(TokenKind::DoubleQuote) {
        parse_string_literal(p)
    } else if p.at(TokenKind::SingleQuote) {
        parse_char_literal(p)
    } else if p.at(TokenKind::Ident) {
        parse_var_ref(p)
    } else if p.at(TokenKind::Caret) {
        parse_ref(p, recovery_set)
    } else if p.at(TokenKind::Mut) {
        parse_mut(p, recovery_set)
    } else if p.at(TokenKind::Hash) {
        parse_directive(p)
    } else if p.at(TokenKind::Distinct) {
        parse_distinct(p, recovery_set)
    } else if p.at(TokenKind::Comptime) {
        parse_comptime(p)
    } else if p.at(TokenKind::Struct) {
        parse_struct_decl(p, recovery_set)
    } else if p.at(TokenKind::Enum) {
        parse_enum_decl(p, recovery_set)
    } else if p.at(TokenKind::Question) {
        parse_optional_decl(p, recovery_set)
    } else if p.at_set(PREFIX_TOKENS) {
        parse_prefix_expr(p, recovery_set)
    } else if p.at(TokenKind::If) {
        parse_if(
            p,
            recovery_set.union(TokenSet::new([TokenKind::If, TokenKind::Else])),
        )
    } else if p.at_set(LOOP_TOKENS) {
        parse_loop(p, None, recovery_set)
    } else if p.at(TokenKind::Switch) {
        parse_switch(p, recovery_set)
    } else if p.at(TokenKind::LParen) {
        parse_lambda(p, recovery_set)
    } else if p.at(TokenKind::LBrack) {
        parse_array_decl(p, recovery_set)
    } else if p.at(TokenKind::LBrace) {
        parse_block(p, None, recovery_set)
    } else if p.at(TokenKind::Dot) && p.at_ahead(1, TokenSet::new([TokenKind::LParen])) {
        // this will just report an error
        parse_cast(p, None, recovery_set)
    } else if p.at(TokenKind::Dot) && p.at_ahead(1, TokenSet::new([TokenKind::LBrack])) {
        parse_array_literal(p, None, recovery_set, None)
    } else if p.at(TokenKind::Dot) && p.at_ahead(1, TokenSet::new([TokenKind::LBrace])) {
        parse_struct_literal(p, None, recovery_set)
    } else if p.at(TokenKind::Backtick) {
        let label = p.start();
        p.bump();

        let _guard = p.expected_syntax_name("label name");
        p.expect_with_no_skip(TokenKind::Ident);

        p.expect_with_no_skip(TokenKind::Colon);

        let label = label.complete(p, NodeKind::LabelDecl);

        if p.at_set(LOOP_TOKENS) {
            parse_loop(p, Some(label), recovery_set)
        } else if p.at(TokenKind::LBrace) {
            parse_block(p, Some(label), recovery_set)
        } else {
            let _guard = p.expected_syntax_name("block");
            p.error_with_no_skip();

            return parse_lhs(p, recovery_set, expected_syntax_name);
        }
    } else {
        // println!("error {:?} {} {:?}", p.peek(), p.at_eof(), p.peek_range());
        return p.error_with_recovery_set(recovery_set);
    };

    Some(cm)
}

// `disallow_derefs` disallows `foo^` expressions to be generated
// `disallow_dot_instantiation` disallows `foo.()`, `foo.{}`, and `foo.[]` expressions to be generated
fn parse_post_operators(
    p: &mut Parser,
    recovery_set: TokenSet,
    cm: CompletedMarker,
    disallow_derefs: bool,
    disallow_dot_instantiation: bool,
) -> CompletedMarker {
    let mut cm = cm;

    // the ONLY reason this is included is to recover when parsing older syntax
    if matches!(cm.kind(), NodeKind::VarRef)
        && !recovery_set.contains(TokenKind::LBrace)
        && p.at(TokenKind::LBrace)
    {
        let ty_cm = cm.precede(p).complete(p, NodeKind::Ty);
        cm = parse_struct_literal(p, Some(ty_cm), recovery_set);
    }

    loop {
        match p.kind() {
            Some(TokenKind::LBrack) => {
                if p.at_ahead(2, TokenSet::new([TokenKind::Comma])) {
                    let ty_cm = cm.precede(p).complete(p, NodeKind::Ty);
                    cm = parse_array_literal(p, Some(ty_cm), recovery_set, None)
                } else {
                    let indexing_expr = cm.precede(p).complete(p, NodeKind::Source).precede(p);
                    p.bump();

                    let real_index = p.start();
                    parse_expr(p, "array index");
                    real_index.complete(p, NodeKind::Index);

                    p.expect_with_no_skip(TokenKind::RBrack);

                    cm = indexing_expr.complete(p, NodeKind::IndexExpr);
                }
            }
            Some(TokenKind::LParen) => {
                let call = cm.precede(p);

                let arg_list_m = p.start();

                p.bump();

                // collect arguments
                loop {
                    if p.at(TokenKind::RParen) {
                        break;
                    }
                    if let Some(arg_m) = expr::parse_expr(p, "argument") {
                        arg_m.precede(p).complete(p, NodeKind::Arg);
                    }

                    if p.at_eof() || p.at_default_recovery_set() {
                        break;
                    }

                    if !p.at(TokenKind::RParen) {
                        p.expect_with_no_skip(TokenKind::Comma);
                    }
                }

                p.expect(TokenKind::RParen);

                arg_list_m.complete(p, NodeKind::ArgList);

                cm = call.complete(p, NodeKind::Call);
            }
            Some(TokenKind::Caret) if !disallow_derefs => {
                let deref = cm.precede(p);
                p.bump();
                cm = deref.complete(p, NodeKind::DerefExpr);
            }
            // this is included so that old syntax is still correctly parsed
            // and an error can be reported
            Some(TokenKind::As) if !disallow_derefs => {
                let cast = cm.precede(p);
                p.bump();

                parse_ty(p, "cast type", recovery_set);

                cm = cast.complete(p, NodeKind::CastExpr);

                let end_token = p.token_idx.saturating_sub(1).max(cm.start_token_idx());

                p.mark_old_unexpected(
                    NodeKind::CastExpr,
                    cm.start_token_idx(),
                    end_token,
                    crate::ExpectedSyntax::Named("`.( )` cast syntax"),
                );
            }
            // todo: should this be implemented as a binary expression?
            Some(TokenKind::Bang) => {
                // todo: report unclear types later
                // if cm.kind() == NodeKind::ErrorUnionDecl {
                //
                // }

                let ty_cm = cm.precede(p).complete(p, NodeKind::Ty);
                let err_ty_cm = ty_cm.precede(p).complete(p, NodeKind::ErrorTy);
                let error_union = err_ty_cm.precede(p);
                p.bump();

                if let Some(ty) = parse_ty(p, "payload type", recovery_set) {
                    ty.precede(p).complete(p, NodeKind::PayloadTy);
                }

                cm = error_union.complete(p, NodeKind::ErrorUnionDecl);
            }
            Some(TokenKind::Dot) => {
                if p.at_ahead(1, TokenSet::new([TokenKind::LParen])) {
                    if disallow_dot_instantiation {
                        break;
                    }
                    let ty_cm = cm.precede(p).complete(p, NodeKind::Ty);
                    cm = parse_cast(p, Some(ty_cm), recovery_set)
                } else if p.at_ahead(1, TokenSet::new([TokenKind::LBrace])) {
                    if disallow_dot_instantiation {
                        break;
                    }
                    let ty_cm = cm.precede(p).complete(p, NodeKind::Ty);
                    cm = parse_struct_literal(p, Some(ty_cm), recovery_set)
                } else if p.at_ahead(1, TokenSet::new([TokenKind::LBrack])) {
                    if disallow_dot_instantiation {
                        break;
                    }
                    let ty_cm = cm.precede(p).complete(p, NodeKind::Ty);
                    cm = parse_array_literal(p, Some(ty_cm), recovery_set, None)
                } else if p.at_ahead(1, TokenSet::new([TokenKind::Try])) {
                    let propagate = cm.precede(p);
                    p.bump();
                    p.bump();
                    cm = propagate.complete(p, NodeKind::PropagateExpr);
                } else {
                    let path = cm.precede(p);
                    p.bump();

                    if p.at(TokenKind::Ident) {
                        p.bump();
                    } else {
                        let _guard = p.expected_syntax_name("field name");
                        p.error_with_no_skip();
                    }

                    cm = path.complete(p, NodeKind::Path);
                }
            }
            _ => break,
        }
    }

    // same as above.
    // i kinda forgot why i included two of these here but i'm sure it's important
    if matches!(cm.kind(), NodeKind::Path | NodeKind::VarRef)
        && !recovery_set.contains(TokenKind::LBrace)
        && p.at(TokenKind::LBrace)
    {
        let ty_cm = cm.precede(p).complete(p, NodeKind::Ty);
        cm = parse_struct_literal(p, Some(ty_cm), recovery_set);
    }

    cm
}

fn parse_int_literal(p: &mut Parser) -> CompletedMarker {
    assert!(p.at(TokenKind::Int) || p.at(TokenKind::Hex) || p.at(TokenKind::Bin));
    let m = p.start();
    p.bump();
    m.complete(p, NodeKind::IntLiteral)
}

fn parse_float_literal(p: &mut Parser) -> CompletedMarker {
    assert!(p.at(TokenKind::Float));
    let m = p.start();
    p.bump();
    m.complete(p, NodeKind::FloatLiteral)
}

fn parse_bool_literal(p: &mut Parser) -> CompletedMarker {
    assert!(p.at(TokenKind::Bool));
    let m = p.start();
    p.bump();
    m.complete(p, NodeKind::BoolLiteral)
}

pub(crate) fn parse_string_literal(p: &mut Parser) -> CompletedMarker {
    assert!(p.at(TokenKind::DoubleQuote));
    let m = p.start();
    p.bump();

    while p.at(TokenKind::StringContents) || p.at(TokenKind::Escape) {
        p.bump();
    }

    p.expect(TokenKind::DoubleQuote);
    m.complete(p, NodeKind::StringLiteral)
}

pub(crate) fn parse_char_literal(p: &mut Parser) -> CompletedMarker {
    assert!(p.at(TokenKind::SingleQuote));
    let m = p.start();
    p.bump();

    while p.at(TokenKind::StringContents) || p.at(TokenKind::Escape) {
        p.bump();
    }

    p.expect(TokenKind::SingleQuote);
    m.complete(p, NodeKind::CharLiteral)
}

fn parse_ref(p: &mut Parser, recovery_set: TokenSet) -> CompletedMarker {
    assert!(p.at(TokenKind::Caret));
    let m = p.start();
    p.bump();

    if p.at(TokenKind::Mut) {
        p.bump();
    }

    // true so `^u64.(42)` gets parsed as `(^u64).(42)` and not `^(u64.(42))`
    parse_expr_for_prefix(p, recovery_set, "operand", true);

    m.complete(p, NodeKind::RefExpr)
}

fn parse_mut(p: &mut Parser, recovery_set: TokenSet) -> CompletedMarker {
    let start_idx = p.token_idx;

    assert!(p.at(TokenKind::Mut));
    let m = p.start();
    p.bump();

    // true so `mut rawptr.(42)` gets parsed as `(mut rawptr).(42)` and not `mut (rawptr.(42))`
    let expr = parse_expr_for_prefix(p, recovery_set, "operand", true);

    // anything other than `mut rawptr` will produce an error
    if !expr.is_some_and(|expr| {
        expr.kind() == NodeKind::VarRef && p.text(expr.start_token_idx()) == "rawptr"
    }) {
        p.mark_old_missing(start_idx, ExpectedSyntax::Unnamed(TokenKind::Caret));
    }

    m.complete(p, NodeKind::MutExpr)
}

fn parse_distinct(p: &mut Parser, recovery_set: TokenSet) -> CompletedMarker {
    assert!(p.at(TokenKind::Distinct));
    let m = p.start();
    p.bump();

    parse_ty(p, "type", recovery_set);

    m.complete(p, NodeKind::Distinct)
}

// fn parse_import_or_mod(p: &mut Parser) -> CompletedMarker {
//     assert!(p.at_set(TokenSet::new([TokenKind::Import, TokenKind::Mod])));
//     let m = p.start();
//     p.bump();
//
//     if p.at(TokenKind::DoubleQuote) {
//         expr::parse_string_literal(p);
//     } else {
//         let _guard = p.expected_syntax_name("file name string");
//         p.error();
//     }
//
//     m.complete(p, NodeKind::ImportExpr)
// }

fn parse_var_ref(p: &mut Parser) -> CompletedMarker {
    assert!(p.at(TokenKind::Ident));
    let m = p.start();

    let start_idx = p.token_idx;

    p.bump();

    // this is to recover from the old import syntax
    let name = p.text(p.token_idx - 1);
    let is_import = name == "import";
    let is_mod = name == "mod";

    if (is_mod || is_import) && p.at(TokenKind::DoubleQuote) {
        p.mark_old_missing(start_idx, ExpectedSyntax::Unnamed(TokenKind::Hash));
        p.expect_with_no_skip(TokenKind::LParen);

        let arg_list_m = p.start();
        if let Some(arg_m) = expr::parse_expr(p, "argument") {
            arg_m.precede(p).complete(p, NodeKind::Arg);
        }
        p.expect_with_no_skip(TokenKind::RParen);
        arg_list_m.complete(p, NodeKind::ArgList);

        m.complete(p, NodeKind::Directive)
    } else {
        m.complete(p, NodeKind::VarRef)
    }
}

fn parse_prefix_expr(p: &mut Parser, recovery_set: TokenSet) -> CompletedMarker {
    assert!(p.at_set(PREFIX_TOKENS));

    let should_allow_dot_instantiation = p.at_set(PREFIX_DISALLOW_DOT);

    let m = p.start();

    // Eat the operator’s token.
    p.bump();
    parse_expr_for_prefix(p, recovery_set, "operand", should_allow_dot_instantiation);
    m.complete(p, NodeKind::UnaryExpr)
}

fn parse_optional_decl(p: &mut Parser, recovery_set: TokenSet) -> CompletedMarker {
    assert!(p.at(TokenKind::Question));

    let m = p.start();

    // Eat the operator’s token.
    p.bump();
    parse_ty(p, "optional type", recovery_set);
    m.complete(p, NodeKind::OptionalDecl)
}

fn parse_lambda(p: &mut Parser, recovery_set: TokenSet) -> CompletedMarker {
    assert!(p.at(TokenKind::LParen));

    // detect if this lambda is really a parenthetical expression
    'detect_paren: {
        let mut depth = 1;
        let saved_idx = p.token_idx;

        let mut had_param_tokens = false;
        let mut had_non_param_tokens = false;

        // this is a hard distinction to make, the main telltale is if the lambda has a return type or
        // if it has a body
        loop {
            p.token_idx += 1;

            if depth == 0 {
                break;
            }

            let Some(kind) = p.peek() else {
                p.token_idx = saved_idx;
                if !had_param_tokens && had_non_param_tokens {
                    return parse_paren(p, recovery_set);
                } else {
                    break 'detect_paren;
                }
            };

            // only a parameter list could have these tokens
            const PARAM_ONLY: TokenSet =
                TokenSet::new([TokenKind::Colon, TokenKind::Comma, TokenKind::Ellipsis]);

            if depth == 1 && kind != TokenKind::RParen {
                if PARAM_ONLY.contains(kind) {
                    had_param_tokens = true;
                } else {
                    had_non_param_tokens = true;
                }
            }

            match kind {
                TokenKind::LParen | TokenKind::LBrack | TokenKind::LBrace => {
                    depth += 1;
                }
                TokenKind::RParen | TokenKind::RBrack | TokenKind::RBrace => {
                    depth -= 1;
                }
                _ => {}
            }
        }

        // the top level of the parentheses contained no idents, colons, or commas
        // but did contain other tokens
        if !had_param_tokens && had_non_param_tokens {
            p.token_idx = saved_idx;
            return parse_paren(p, recovery_set);
        }

        if had_param_tokens {
            p.token_idx = saved_idx;
            break 'detect_paren;
        }

        let Some(kind) = p.peek() else {
            p.token_idx = saved_idx;
            return parse_paren(p, recovery_set);
        };

        const AFTER_PARAMS: TokenSet = TokenSet::new([
            TokenKind::Arrow,
            TokenKind::LBrace,
            TokenKind::Extern,
            TokenKind::Hash,
        ]);

        if !AFTER_PARAMS.contains(kind) {
            p.token_idx = saved_idx;
            return parse_paren(p, recovery_set);
        } else {
            p.token_idx = saved_idx;
        }
    }

    let m = p.start();

    let param_list_m = p.start();

    p.bump();

    const PARAM_RECOVERY_SET: TokenSet =
        TokenSet::new([TokenKind::Comma, TokenKind::RParen, TokenKind::Ellipsis]);

    loop {
        if p.at(TokenKind::RParen) {
            break;
        }

        let param_m = p.start();
        {
            let _guard = p.expected_syntax_name("parameter name");
            p.expect_with_recovery_set(TokenKind::Ident, PARAM_RECOVERY_SET);
        }

        p.expect_with_no_skip(TokenKind::Colon);

        if p.at(TokenKind::Ellipsis) {
            p.bump();
        }

        parse_ty(p, "parameter type", PARAM_RECOVERY_SET);

        param_m.complete(p, NodeKind::Param);

        if p.at_eof() || p.at_default_recovery_set() {
            break;
        }

        if !p.at(TokenKind::RParen) {
            p.expect_with_no_skip(TokenKind::Comma);
        }
    }
    p.expect_with_recovery_set(
        TokenKind::RParen,
        TokenSet::new([TokenKind::Arrow, TokenKind::LBrace, TokenKind::Hash]),
    );

    param_list_m.complete(p, NodeKind::ParamList);

    const BODY: TokenSet = TokenSet::new([TokenKind::LBrace, TokenKind::Extern, TokenKind::Hash]);

    if !p.at_set(BODY) {
        p.expect_with_no_skip(TokenKind::Arrow);

        if !p.at_set(BODY) {
            parse_ty(
                p,
                "return type",
                recovery_set.union(TokenSet::new([TokenKind::LBrace])),
            );
        } else {
            let _guard = p.expected_syntax_name("return type");
            p.error_with_no_skip();
        }
    }

    if p.at(TokenKind::LBrace) {
        parse_block(p, None, recovery_set);
    } else if p.at(TokenKind::Hash) {
        parse_directive(p);
    } else if p.at(TokenKind::Extern) {
        p.bump();
    }

    m.complete(p, NodeKind::Lambda)
}

fn parse_paren(p: &mut Parser, recovery_set: TokenSet) -> CompletedMarker {
    assert!(p.at(TokenKind::LParen));

    let m = p.start();
    p.bump();

    if p.at(TokenKind::RParen) {
        p.bump();
        return m.complete(p, NodeKind::ParenExpr);
    }

    parse_expr_with_recovery_set(p, "expression", recovery_set);

    p.expect_with_no_skip(TokenKind::RParen);
    m.complete(p, NodeKind::ParenExpr)
}

// todo: allow ^u64.(foo) to parse correctly
fn parse_cast(
    p: &mut Parser,
    previous_ty: Option<CompletedMarker>,
    recovery_set: TokenSet,
) -> CompletedMarker {
    if let Some(previous_ty) = previous_ty {
        assert_eq!(previous_ty.kind(), NodeKind::Ty);
    } else {
        let _guard = p.expected_syntax_name("type");
        p.error_with_no_skip();
    }

    let at_dot = p.at(TokenKind::Dot);
    let next_paren = p.at_ahead(1, TokenSet::new([TokenKind::LParen]));

    assert!(at_dot && next_paren);

    let m = previous_ty
        .map(|ty| ty.precede(p))
        .unwrap_or_else(|| p.start());

    // we already asserted before, so this is safe
    p.bump();
    p.bump();

    if !p.at(TokenKind::RParen) {
        parse_expr_with_recovery_set(
            p,
            "cast value",
            recovery_set.union(TokenSet::new([TokenKind::Comma, TokenKind::RParen])),
        );
    }

    p.expect_with_recovery_set(TokenKind::RParen, recovery_set);

    m.complete(p, NodeKind::CastExpr)
}

fn parse_struct_decl(p: &mut Parser, recovery_set: TokenSet) -> CompletedMarker {
    assert!(p.at(TokenKind::Struct));

    let m = p.start();

    p.bump();

    if p.at(TokenKind::LBrace) {
        p.bump();
    } else {
        let _guard = p.expected_syntax_name("struct body");
        p.error_with_recovery_set(recovery_set);

        return m.complete(p, NodeKind::StructDecl);
    }

    loop {
        if p.at(TokenKind::RBrace) {
            break;
        }

        let field_m = p.start();
        let _guard = p.expected_syntax_name("field name");
        p.expect(TokenKind::Ident);

        p.expect_with_no_skip(TokenKind::Colon);

        parse_ty(
            p,
            "field type",
            recovery_set.union(TokenSet::new([TokenKind::Comma, TokenKind::RBrace])),
        );

        field_m.complete(p, NodeKind::MemberDecl);

        if p.at_eof() || p.at_default_recovery_set() {
            break;
        }

        if !p.at(TokenKind::RBrace) {
            p.expect_with_no_skip(TokenKind::Comma);
        }
    }
    p.expect(TokenKind::RBrace);

    m.complete(p, NodeKind::StructDecl)
}

fn parse_struct_literal(
    p: &mut Parser,
    previous_ty: Option<CompletedMarker>,
    recovery_set: TokenSet,
) -> CompletedMarker {
    if let Some(previous_ty) = previous_ty {
        assert_eq!(previous_ty.kind(), NodeKind::Ty);
    }

    let at_dot = p.at(TokenKind::Dot);
    let at_lbrace = p.at(TokenKind::LBrace);
    let next_lbrace = p.at_ahead(1, TokenSet::new([TokenKind::LBrace]));

    if at_dot {
        assert!(next_lbrace);
    } else {
        assert!(at_lbrace);
    }

    let m = previous_ty
        .map(|ty| ty.precede(p))
        .unwrap_or_else(|| p.start());

    p.expect_with_no_skip(TokenKind::Dot);
    p.bump();

    loop {
        if p.at(TokenKind::RBrace) {
            break;
        }

        let field_m = p.start();
        let _guard = p.expected_syntax_name("field name");
        p.expect_with_no_skip(TokenKind::Ident);

        if p.at(TokenKind::Colon) {
            p.expect(TokenKind::Equals);
        } else {
            p.expect_with_no_skip(TokenKind::Equals);
        }

        parse_expr_with_recovery_set(
            p,
            "field value",
            recovery_set.union(TokenSet::new([TokenKind::Comma, TokenKind::RBrace])),
        );

        field_m.complete(p, NodeKind::MemberLiteral);

        if p.at_eof() || p.at_default_recovery_set() {
            break;
        }

        if !p.at(TokenKind::RBrace) {
            p.expect_with_no_skip(TokenKind::Comma);
        }
    }
    p.expect_with_recovery_set(TokenKind::RBrace, recovery_set);

    m.complete(p, NodeKind::StructLiteral)
}

fn parse_enum_decl(p: &mut Parser, recovery_set: TokenSet) -> CompletedMarker {
    assert!(p.at(TokenKind::Enum));

    let m = p.start();

    p.bump();

    if p.at(TokenKind::LBrace) {
        p.bump();
    } else {
        let _guard = p.expected_syntax_name("enum body");
        p.error_with_recovery_set(recovery_set);

        return m.complete(p, NodeKind::EnumDecl);
    }

    loop {
        if p.at(TokenKind::RBrace) {
            break;
        }

        let variant_m = p.start();
        let _guard = p.expected_syntax_name("variant name");
        p.expect(TokenKind::Ident);

        if p.at(TokenKind::Colon) {
            p.bump();

            parse_ty(
                p,
                "variant type",
                recovery_set.union(TokenSet::new([TokenKind::Comma, TokenKind::RBrace])),
            );
        }

        if p.at(TokenKind::Pipe) {
            let discriminant_m = p.start();
            p.bump();

            parse_expr(p, "custom discriminant");

            discriminant_m.complete(p, NodeKind::Discriminant);
        }

        variant_m.complete(p, NodeKind::VariantDecl);

        if p.at_eof() || p.at_default_recovery_set() {
            break;
        }

        if !p.at(TokenKind::RBrace) {
            p.expect_with_no_skip(TokenKind::Comma);
        }
    }
    p.expect(TokenKind::RBrace);

    m.complete(p, NodeKind::EnumDecl)
}

/// `array_decl` is ONLY used by `parse_array_decl` to pass it's previously created marker.
/// This allows the array literal to completely replace the array declaration.
///
/// If previous_ty is set to None, this will be treated as an untyped array literal
/// `.[1, 2, 3]`
fn parse_array_literal(
    p: &mut Parser,
    previous_ty: Option<CompletedMarker>,
    recovery_set: TokenSet,
    array_decl: Option<Marker>,
) -> CompletedMarker {
    if let Some(previous_ty) = previous_ty {
        assert_eq!(previous_ty.kind(), NodeKind::Ty);
    }

    let at_dot = p.at(TokenKind::Dot);
    let at_lbrace = p.at(TokenKind::LBrace);
    let at_lbrack = p.at(TokenKind::LBrack);
    let next_lbrack = p.at_ahead(1, TokenSet::new([TokenKind::LBrack]));

    if at_dot {
        assert!(next_lbrack);
    } else {
        assert!(at_lbrace || at_lbrack);
    }

    let m = array_decl
        .or_else(|| previous_ty.map(|ty| ty.precede(p)))
        .unwrap_or_else(|| p.start());

    const DEFAULT_NO_BRACES: TokenSet = crate::parser::DEFAULT_RECOVERY_SET
        .without(TokenKind::LBrace)
        .without(TokenKind::RBrace);

    p.expect_with_no_skip(TokenKind::Dot);
    // if we are `at_lbrace` this will report an error
    p.expect_with_recovery_set_no_default(TokenKind::LBrack, DEFAULT_NO_BRACES);

    loop {
        if p.at(TokenKind::RBrack) || p.at(TokenKind::RBrace) {
            break;
        }

        if let Some(item) = parse_expr_with_recovery_set(p, "array item", recovery_set) {
            item.precede(p).complete(p, NodeKind::ArrayItem);
        }

        if p.at_eof() || p.at_default_recovery_set() {
            break;
        }

        if !p.at(TokenKind::RBrack) && !p.at(TokenKind::RBrace) {
            p.expect_with_no_skip(TokenKind::Comma);
        }
    }
    p.expect_with_recovery_set_no_default(TokenKind::RBrack, DEFAULT_NO_BRACES);

    m.complete(p, NodeKind::ArrayLiteral)
}

fn parse_array_decl(p: &mut Parser, recovery_set: TokenSet) -> CompletedMarker {
    assert!(p.at(TokenKind::LBrack));

    let array = p.start();

    let size = p.start();
    let size_start = p.token_idx;
    p.bump();

    if !p.at(TokenKind::RBrack) {
        parse_expr(p, "array size");
    }

    p.expect_with_recovery_set(
        TokenKind::RBrack,
        recovery_set.union(TokenSet::new([TokenKind::LBrace])),
    );

    size.complete(p, NodeKind::ArraySize);
    let size_end = p.token_idx;

    let ty = parse_ty(
        p,
        "array type",
        recovery_set.union(TokenSet::new([TokenKind::LBrace])),
    );

    // make sure someone isn't using the wrong syntax
    match ty {
        Some(ty) if !recovery_set.contains(TokenKind::LBrace) && p.at(TokenKind::LBrace) => {
            p.mark_old_unexpected(
                NodeKind::ArraySize,
                size_start,
                size_end,
                crate::ExpectedSyntax::Named("nothing"),
            );
            parse_array_literal(p, Some(ty), recovery_set, Some(array))
        }
        _ => array.complete(p, NodeKind::ArrayDecl),
    }
}

fn parse_if(p: &mut Parser, recovery_set: TokenSet) -> CompletedMarker {
    assert!(p.at(TokenKind::If));

    let m = p.start();
    p.bump();

    parse_expr_with_recovery_set(
        p,
        "condition",
        recovery_set.union(TokenSet::new([TokenKind::LBrace])),
    );

    if p.at(TokenKind::LBrace) {
        parse_block(p, None, recovery_set);
    } else {
        let _guard = p.expected_syntax_name("if body");
        p.error_with_recovery_set(recovery_set);
    }

    if p.at(TokenKind::Else) {
        let else_m = p.start();
        p.bump();

        if p.at(TokenKind::If) {
            parse_if(p, recovery_set);
        } else if p.at(TokenKind::LBrace) {
            parse_block(p, None, recovery_set);
        } else {
            let _guard = p.expected_syntax_name("else body");
            p.error_with_recovery_set(recovery_set);
        }

        else_m.complete(p, NodeKind::ElseBranch);
    }

    m.complete(p, NodeKind::IfExpr)
}

fn parse_loop(
    p: &mut Parser,
    label: Option<CompletedMarker>,
    recovery_set: TokenSet,
) -> CompletedMarker {
    let at_while = p.at(TokenKind::While);
    let at_loop = p.at(TokenKind::Loop);
    assert!(at_while || at_loop);

    let m = if let Some(label) = label {
        label.precede(p)
    } else {
        p.start()
    };

    p.bump();

    if at_while {
        let m = p.start();
        parse_expr_with_recovery_set(
            p,
            "condition",
            recovery_set.union(TokenSet::new([TokenKind::LBrace])),
        );
        m.complete(p, NodeKind::Condition);
    }

    if p.at(TokenKind::LBrace) {
        parse_block(p, None, recovery_set);
    } else {
        let _guard = if at_while {
            p.expected_syntax_name("while body")
        } else {
            p.expected_syntax_name("loop body")
        };
        p.error_with_recovery_set(recovery_set);
    }

    m.complete(p, NodeKind::WhileExpr)
}

fn parse_switch(p: &mut Parser, recovery_set: TokenSet) -> CompletedMarker {
    assert!(p.at(TokenKind::Switch));

    let m = p.start();
    p.bump();

    if p.at(TokenKind::Ident)
        && (p.at_ahead(1, TokenSet::new([TokenKind::In])) || p.at_eof_ahead(1))
    {
        // todo: pick better syntax name
        let _guard = p.expected_syntax_name("switch parameter name");
        p.expect(TokenKind::Ident);

        p.expect_with_recovery_set(
            TokenKind::In,
            recovery_set.union(TokenSet::new([TokenKind::LBrace])),
        );
    }

    // todo: pick better syntax name
    parse_expr_with_recovery_set(
        p,
        "enum value",
        recovery_set.union(TokenSet::new([TokenKind::LBrace])),
    );

    if p.at(TokenKind::LBrace) {
        p.bump();

        loop {
            if p.at(TokenKind::RBrace) {
                break;
            }

            let arm_m = p.start();
            // todo: catch shorthand cases where the dot is missing
            if p.at(TokenKind::Dot) {
                let shorthand_m = p.start();
                p.expect_with_no_skip(TokenKind::Dot);

                let _guard = p.expected_syntax_name("enum variant name");
                p.expect(TokenKind::Ident);

                shorthand_m.complete(p, NodeKind::VariantShorthand);
            } else if p.at(TokenKind::Ident) && p.text(p.token_idx) == "_" {
                let default_m = p.start();
                p.bump();
                default_m.complete(p, NodeKind::DefaultArm);
            } else {
                parse_ty(
                    p,
                    "variant",
                    recovery_set.union(TokenSet::new([TokenKind::FatArrow])),
                );
            }

            p.expect_with_no_skip(TokenKind::FatArrow);

            parse_expr_with_recovery_set(p, "switch arm", recovery_set);

            arm_m.complete(p, NodeKind::SwitchArm);

            if p.at_eof() || p.at_default_recovery_set() {
                break;
            }

            // switch blocks must always end with commas because otherwise shorthand variants might
            // attach themselves to the last block as paths
            if !p.at(TokenKind::RBrace) || p.at(TokenKind::Comma) {
                p.expect_with_no_skip(TokenKind::Comma);
            }
        }

        p.expect_with_recovery_set(TokenKind::RBrace, recovery_set);
    } else {
        let _guard = p.expected_syntax_name("switch body");
        p.error_with_recovery_set(recovery_set);
    }

    m.complete(p, NodeKind::SwitchExpr)
}

fn parse_comptime(p: &mut Parser) -> CompletedMarker {
    assert!(p.at(TokenKind::Comptime));

    let m = p.start();
    p.bump();

    parse_expr(p, "comptime body");

    m.complete(p, NodeKind::ComptimeExpr)
}

fn parse_block(
    p: &mut Parser,
    label: Option<CompletedMarker>,
    recovery_set: TokenSet,
) -> CompletedMarker {
    assert!(p.at(TokenKind::LBrace));

    let m = if let Some(label) = label {
        label.precede(p)
    } else {
        p.start()
    };

    p.bump();

    while !p.at(TokenKind::RBrace) && !p.at_eof() {
        stmt::parse_stmt(p, false);
    }

    p.expect_with_recovery_set(TokenKind::RBrace, recovery_set);

    m.complete(p, NodeKind::Block)
}

fn parse_directive(p: &mut Parser) -> CompletedMarker {
    assert!(p.at(TokenKind::Hash));
    let m = p.start();
    p.bump();

    p.expect_with_no_skip(TokenKind::Ident);

    let arg_list_m = p.start();

    p.expect_with_no_skip(TokenKind::LParen);

    // collect arguments
    loop {
        if p.at(TokenKind::RParen) {
            break;
        }
        if let Some(arg_m) = expr::parse_expr(p, "argument") {
            arg_m.precede(p).complete(p, NodeKind::Arg);
        }

        if p.at_eof() || p.at_default_recovery_set() {
            break;
        }

        if !p.at(TokenKind::RParen) {
            p.expect_with_no_skip(TokenKind::Comma);
        }
    }

    p.expect(TokenKind::RParen);

    arg_list_m.complete(p, NodeKind::ArgList);

    m.complete(p, NodeKind::Directive)
}
